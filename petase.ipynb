{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0f89a1",
   "metadata": {},
   "source": [
    "Loading data (Uniprot / Mgnify / NCBI) from a IDs input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bdd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"justin.neo2@gmail.com\"   # required by NCBI\n",
    "OUTPUT_FILE = \"erickson_petasevariant.fasta\"\n",
    "#Some entries like R4YKL9_OLEAN, E9LVI0_THEFU, Q47RJ6_THEFY are UniProt accession + organism suffix.\n",
    "#The REST API expects only the accession (R4YKL9, E9LVI0, Q47RJ6) — not the _XXXX part.\n",
    "# read IDs from file, pre-clean the     IDs to remove any .1 .2 etc. \n",
    "#some IDs are in a different format than the one REST needs, on uniprot use the entry name strictly  \n",
    "#\n",
    "with open(\"petase_db/erickson_petasevariant_id.txt\") as f:\n",
    "    ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "#UNIPROT \n",
    "def fetch_uniprot(uid):\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uid}.fasta\"\n",
    "    r = requests.get(url)\n",
    "    return r.text if r.status_code == 200 else None\n",
    "\n",
    "#MGNIFY\n",
    "def fetch_mgnify(mid):\n",
    "    url = f\"https://www.ebi.ac.uk/metagenomics/api/latest/sequence/{mid}.fasta\"\n",
    "    r = requests.get(url)\n",
    "    return r.text if r.status_code == 200 else None\n",
    "\n",
    "#ENTREZ NCBI \n",
    "def fetch_ncbi(nid):\n",
    "    for db in [\"protein\", \"nuccore\"]:\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=db, id=nid, rettype=\"fasta\", retmode=\"text\")\n",
    "            fasta = handle.read()\n",
    "            if fasta.strip():\n",
    "                return fasta\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as out:\n",
    "    for seq_id in ids:\n",
    "        print(f\"Fetching {seq_id} ...\")\n",
    "        fasta = None\n",
    "        #if seq_id.startswith((\"A0\", \"Q\", \"P\", \"E\")) or seq_id == \"MPZ00478\" or seq_id == \"MBO9532528\" or seq_id == \"MBX2857432\" or seq_id == \"MBX3625601\":\n",
    "        #    fasta = fetch_uniprot(seq_id)\n",
    "        #elif seq_id.startswith((\"MGYP\", \"MBX\", \"MBO\", \"MPZ\")):\n",
    "        #    fasta = fetch_mgnify(seq_id)\n",
    "        #else:\n",
    "        #    fasta = fetch_ncbi(seq_id)\n",
    "        fasta = fetch_ncbi(seq_id)\n",
    "        if fasta is None:\n",
    "            print(f\"⚠️ Could not fetch {seq_id}\")\n",
    "        else:\n",
    "            out.write(fasta)\n",
    "\n",
    "print(f\"✅ Done! Sequences saved in {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062fdb2",
   "metadata": {},
   "source": [
    "Unified PETase seq from Uniprotec + Pazy\n",
    "\n",
    "100: 464\n",
    "\n",
    "cd-hit 0.99: 489 ->  457\n",
    "\n",
    "0.98: 446\n",
    "\n",
    "0.97: 434\n",
    "\n",
    "0.96: 422\n",
    "\n",
    "95: 413 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92c236",
   "metadata": {},
   "source": [
    "PETase mutation adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd573c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def apply_mutations_to_fasta(input_fasta, output_fasta, mutations, offset=27):\n",
    "    \"\"\"\n",
    "    Apply a list of mutations (e.g. [\"S121E\", \"D186H\"]) to a FASTA sequence.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str): path to input fasta (with WT sequence)\n",
    "        output_fasta (str): path to save mutated fasta\n",
    "        mutations (list): list of mutation strings (e.g. [\"S121E\", \"D186H\"])\n",
    "        offset (int): numbering offset (e.g. 27 if sequence is signal peptide–trimmed)\n",
    "    \"\"\"\n",
    "\n",
    "    # Read first sequence from fasta\n",
    "    record = next(SeqIO.parse(input_fasta, \"fasta\"))\n",
    "    seq_list = list(str(record.seq))\n",
    "    original_seq = str(record.seq)\n",
    "\n",
    "    applied = []\n",
    "    for mut in mutations:\n",
    "        wt_res = mut[0]            # first letter\n",
    "        new_res = mut[-1]          # last letter\n",
    "        pos = int(mut[1:-1])       # number in between\n",
    "        idx = pos - offset - 1     # adjust and convert to 0-based\n",
    "\n",
    "        if idx < 0 or idx >= len(seq_list):\n",
    "            applied.append((mut, \"⚠️ out of range\"))\n",
    "            continue\n",
    "\n",
    "        if seq_list[idx] != wt_res:\n",
    "            applied.append((mut, f\"⚠️ mismatch: found {seq_list[idx]} at pos {pos}, expected {wt_res}\"))\n",
    "        else:\n",
    "            seq_list[idx] = new_res\n",
    "            applied.append((mut, \"ok\"))\n",
    "\n",
    "    # Make new record\n",
    "    mutated_seq = \"\".join(seq_list)\n",
    "    new_id = record.id + \"_\" + \"_\".join(mutations)\n",
    "    new_record = SeqRecord(Seq(mutated_seq), id=new_id, description=\"Mutated variant\")\n",
    "\n",
    "    # Write FASTA\n",
    "    SeqIO.write(new_record, output_fasta, \"fasta\")\n",
    "\n",
    "    return applied, mutated_seq\n",
    "\n",
    "# Example usage:\n",
    "mutations = [\"T250N\"]\n",
    "applied, mutated_seq = apply_mutations_to_fasta(\n",
    "    \"petase_db/wtcapetase.fasta\",\n",
    "    \"CaPETase_T250N.fasta\",\n",
    "    mutations,\n",
    "    offset=0\n",
    ")\n",
    "\n",
    "print(\"Applied mutations:\")\n",
    "for m in applied:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b96f5be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 34 variants to bhrtest.fasta\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pandas as pd\n",
    "\n",
    "#mutations\n",
    "mutations_bhr = [\n",
    "    \"W104L\",\"W104S\",\"W104C\",\"W104H\",\"W104D\",\"W104R\",\"W104G\",\n",
    "    \"H164L\",\"H164S\",\"H164E\",\"H164Q\",\"H164F\",\n",
    "    \"M166L\",\"M166S\",\"M166D\",\"M166F\",\n",
    "    \"W190L\",\"W190M\",\"W190S\",\"W190H\",\"W190D\",\n",
    "    \"H191L\",\"H191M\",\"H191S\",\"H191D\",\"H191Y\",\n",
    "    \"F243I\",\"F243S\",\"F243T\",\"F243D\",\"F243N\",\"F243G\",\n",
    "    \"H218S\",\"H218S/F222I\"\n",
    "]\n",
    "mutations_son = [\n",
    "    \"S121D\",\n",
    "    \"S121E\",\n",
    "    \"D186H\",\n",
    "    \"D186F\",\n",
    "    \"D186I\",\n",
    "    \"D186L\",\n",
    "    \"D186V\",\n",
    "    \"P181A\",\n",
    "    \"P181G\",\n",
    "    \"P181S\"\n",
    "]\n",
    "\n",
    "mutations_lcc = [\n",
    "    \"T96M\",\n",
    "    \"Y127G\",\n",
    "    \"F243I\",\n",
    "    \"F243W\",\n",
    "    \"N246D\",\n",
    "    \"N246M\",\n",
    "    \"D238C/S283C\",\n",
    "    \"F243I/D238C/S283C\",\n",
    "    \"F243W/D238C/S283C\",\n",
    "    \"F243I/D238C/S283C/T96M\",\n",
    "    \"F243I/D238C/S283C/Y127G\",\n",
    "    \"F243I/D238C/S283C/N246D\",\n",
    "    \"F243I/D238C/S283C/N246M\",\n",
    "    \"F243W/D238C/S283C/T96M\",\n",
    "    \"F243W/D238C/S283C/Y127G\",\n",
    "    \"F243W/D238C/S283C/N246D\",\n",
    "    \"F243W/D238C/S283C/N246M\"\n",
    "]\n",
    "# ---- Input ----\n",
    "wt_fasta = \"petase_db/sequences/wtbhrpetase.fasta\"   # WT FASTA\n",
    "output_fasta = \"bhrtest.fasta\"\n",
    "\n",
    "# ---- Load WT sequence ----\n",
    "wt_record = SeqIO.read(wt_fasta, \"fasta\")\n",
    "wt_seq = list(str(wt_record.seq))\n",
    "\n",
    "OFFSET = 0  # negative offset\n",
    "\n",
    "def apply_mutations(wt_seq, mutations_str):\n",
    "    seq = wt_seq.copy()\n",
    "    for mut in mutations_str.replace(\"+\", \"/\").split(\"/\"):\n",
    "        if not mut:\n",
    "            continue\n",
    "        wt_aa = mut[0]\n",
    "        pos = int(mut[1:-1])\n",
    "        pos += OFFSET   # << now applies negative offset if set\n",
    "        new_aa = mut[-1]\n",
    "        if pos-1 >= len(seq) or pos-1 < 0:\n",
    "            raise ValueError(f\"Mutation {mut} out of range for sequence length {len(seq)} (index {pos-1})\")\n",
    "        if seq[pos-1] != wt_aa:\n",
    "            print(f\"⚠️ Warning: expected {wt_aa} at {pos}, found {seq[pos-1]}\")\n",
    "        seq[pos-1] = new_aa\n",
    "    return \"\".join(seq)\n",
    "\n",
    "# ---- Generate all variants ----\n",
    "records = []\n",
    "for mut in mutations_bhr:\n",
    "    new_seq = apply_mutations(wt_seq, mut)\n",
    "    record = SeqRecord(Seq(new_seq), id=f\"bhrtest_{mut}\", description=mut)\n",
    "    records.append(record)\n",
    "\n",
    "# ---- Write output FASTA ----\n",
    "SeqIO.write(records, output_fasta, \"fasta\")\n",
    "print(f\"✅ Wrote {len(records)} variants to {output_fasta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92789202",
   "metadata": {},
   "source": [
    "PETase mutation scoring for IsPETase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def sequences_position_table(input_fasta, mutations, offset=27):\n",
    "    \"\"\"\n",
    "    Build a table with columns as mutation positions and rows as sequences,\n",
    "    showing the amino acid present at each position.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str): path to FASTA containing one or more sequences\n",
    "        mutations (list): list of mutation strings (e.g., [\"S160\", \"D206A\", \"W159[H/A]\"])\n",
    "        offset (int): numbering offset (subtract this many from the positions)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: table with mutations as columns and sequences as rows\n",
    "    \"\"\"\n",
    "    # Regex to parse mutation\n",
    "    pattern = re.compile(r\"([A-Z])?(\\d+)([A-Z]|\\[[A-Z/]+\\])?\")\n",
    "\n",
    "    # Parse mutation positions once\n",
    "    mut_info = []\n",
    "    for mut in mutations:\n",
    "        m = pattern.match(mut)\n",
    "        if not m:\n",
    "            continue\n",
    "        _, pos, _ = m.groups()\n",
    "        pos = int(pos) - offset\n",
    "        idx = pos - 1\n",
    "        mut_info.append((mut, idx))\n",
    "\n",
    "    # Collect rows for each sequence\n",
    "    rows = []\n",
    "    row_ids = []\n",
    "\n",
    "    for record in SeqIO.parse(input_fasta, \"fasta\"):\n",
    "        seq = str(record.seq)\n",
    "        row_ids.append(record.id)\n",
    "\n",
    "        row_vals = []\n",
    "        for mut, idx in mut_info:\n",
    "            if 0 <= idx < len(seq):\n",
    "                row_vals.append(seq[idx])\n",
    "            else:\n",
    "                row_vals.append(\"NA\")  # if index out of range\n",
    "        rows.append(row_vals)\n",
    "\n",
    "    # Build DataFrame\n",
    "    col_labels = [mut for mut, _ in mut_info]\n",
    "    df = pd.DataFrame(rows, columns=col_labels, index=row_ids)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "mutations = [\n",
    "    \"S160\", \"D206\", \"H237\", \"T88\", \"W159\", \"W185\", \"I208\", \"S214\", \"Y87\", \"M161\",\n",
    "    \"C203\", \"C239\", \"C273\", \"C289\", \"S160A\", \"Y87A\", \"M161A\", \"T88A\", \"W159[H/A]\",\n",
    "    \"W185A\", \"I208A\", \"S214H\", \"C203S\", \"C239S\", \"S160\", \"D206\", \"H237\", \"Y87\",\n",
    "    \"M161\", \"W185\", \"I208\", \"T88\", \"A89\", \"W159\", \"I232\", \"N233\", \"S236\", \"S238F\",\n",
    "    \"N241\", \"N244\", \"S245\", \"N246\", \"R280\", \"S160A\", \"D206A\", \"H237A\", \"Y87A\",\n",
    "    \"M161A\", \"W185A\", \"I208A\", \"W159[H/A]\", \"S238F\", \"N241A\", \"R280A\", \"C203A\",\n",
    "    \"C239A\", \"R90A\", \"L117F\", \"I208F\", \"R280A\", \"W159H\", \"S238F\", \"L117F\", \"R280A\",\n",
    "    \"T88M\", \"Q119G\", \"N233C\", \"S238I\", \"N241D\", \"S282C\"\n",
    "]\n",
    "\n",
    "df = sequences_position_table(\"petase_db/sequences/all_petase_variants.fasta\", mutations, offset=27)\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"petase_mutation_table_allseqs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f5d5c",
   "metadata": {},
   "source": [
    "Mutation scoring for CaPETase variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "def sequences_position_table(input_fasta, positions):\n",
    "    \"\"\"\n",
    "    Build a DataFrame where columns are positions and rows are sequences,\n",
    "    showing the amino acid present at each position.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str): path to FASTA with one or more sequences\n",
    "        positions (list[int]): list of 1-based positions to check\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    row_ids = []\n",
    "\n",
    "    for record in SeqIO.parse(input_fasta, \"fasta\"):\n",
    "        seq = str(record.seq)\n",
    "        row_ids.append(record.id)\n",
    "\n",
    "        row_vals = []\n",
    "        for pos in positions:\n",
    "            if 1 <= pos <= len(seq):\n",
    "                row_vals.append(seq[pos-1])  # convert to 0-based index\n",
    "            else:\n",
    "                row_vals.append(\"NA\")  # if position is out of range\n",
    "        rows.append(row_vals)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[str(p) for p in positions], index=row_ids)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "positions = [169, 246, 215, 194, 223, 227, 101, 102, 103,\n",
    "             107, 133, 168, 170, 195, 196, 217, 247, 250]\n",
    "\n",
    "df = sequences_position_table(\"petase_db/sequences/capetasevariants.fasta\", positions)\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"catase_positions_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4211fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def sequences_mutation_table(input_fasta, mutations, offset=0):\n",
    "    \"\"\"\n",
    "    Build a DataFrame where columns are mutation strings and rows are sequences,\n",
    "    showing the amino acid present at each (offset-adjusted) position.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str): path to FASTA with one or more sequences\n",
    "        mutations (list[str]): mutation strings (e.g., \"S160\", \"D206A\", \"W159[H/A]\")\n",
    "        offset (int): numeric offset to apply to positions (default=0)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Regex to parse strings like S160, D206A, W159[H/A]\n",
    "    pattern = re.compile(r\"([A-Z])?(\\d+)([A-Z]|\\[[A-Z/]+\\])?\")\n",
    "\n",
    "    # Parse mutation strings into (label, adjusted pos)\n",
    "    mut_info = []\n",
    "    for mut in mutations:\n",
    "        m = pattern.match(mut)\n",
    "        if not m:\n",
    "            continue\n",
    "        _, pos, _ = m.groups()\n",
    "        pos = int(pos) + offset  # apply offset\n",
    "        mut_info.append((mut, pos))\n",
    "\n",
    "    rows = []\n",
    "    row_ids = []\n",
    "\n",
    "    for record in SeqIO.parse(input_fasta, \"fasta\"):\n",
    "        seq = str(record.seq)\n",
    "        row_ids.append(record.id)\n",
    "\n",
    "        row_vals = []\n",
    "        for label, pos in mut_info:\n",
    "            if 1 <= pos <= len(seq):\n",
    "                row_vals.append(seq[pos-1])  # 1-based to 0-based index\n",
    "            else:\n",
    "                row_vals.append(\"NA\")\n",
    "        rows.append(row_vals)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[label for label, _ in mut_info], index=row_ids)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "mutations = [\n",
    "    \"S160\", \"D206\", \"H237\", \"T88\", \"W159\", \"W185\", \"I208\", \"S214\", \"Y87\", \"M161\",\n",
    "    \"C203\", \"C239\", \"C273\", \"C289\", \"S160A\", \"Y87A\", \"M161A\", \"T88A\", \"W159[H/A]\",\n",
    "    \"W185A\", \"I208A\", \"S214H\", \"C203S\", \"C239S\", \"S160\", \"D206\", \"H237\", \"Y87\",\n",
    "    \"M161\", \"W185\", \"I208\", \"T88\", \"A89\", \"W159\", \"I232\", \"N233\", \"S236\", \"S238F\",\n",
    "    \"N241\", \"N244\", \"S245\", \"N246\", \"R280\", \"S160A\", \"D206A\", \"H237A\", \"Y87A\",\n",
    "    \"M161A\", \"W185A\", \"I208A\", \"W159[H/A]\", \"S238F\", \"N241A\", \"R280A\", \"C203A\",\n",
    "    \"C239A\", \"R90A\", \"L117F\", \"I208F\", \"R280A\", \"W159H\", \"S238F\", \"L117F\", \"R280A\",\n",
    "    \"T88M\", \"Q119G\", \"N233C\", \"S238I\", \"N241D\", \"S282C\"\n",
    "]\n",
    "\n",
    "df = sequences_mutation_table(\"petase_db/sequences/CaPETasevariants.fasta\", mutations, offset=9)\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"capetase_mutation_check_offset9.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6eb4e",
   "metadata": {},
   "source": [
    "fix mutation list agreement across the pdb-fasta for foldx\n",
    "\n",
    "python fix_mutations_for_pdb.py wtIsPETase_6ilw_Repair.pdb individual_list.txt fixed_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a6f41",
   "metadata": {},
   "source": [
    "Encoding sequences and structures of variants with esm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5bc35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "from huggingface_hub import login\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESM3InferenceClient, ESMProtein, GenerationConfig\n",
    "import torch\n",
    "import esm\n",
    "from esm.sdk import client\n",
    "login(token=\"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\")\n",
    "\n",
    "device = (\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "#Forge API\n",
    "model=client(\"esm3-large-2024-08\",token=\"1hM3JVqy7zILco2fwPgF9v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e48e6",
   "metadata": {},
   "source": [
    "Sequence emebdding esm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52a7d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP\n",
    "import torch\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import pandas as pd \n",
    "from esm.sdk import client\n",
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Sequence\n",
    "from esm.sdk.api import (\n",
    "    ESM3InferenceClient,\n",
    "    ESMProtein,\n",
    "    ESMProteinError,\n",
    "    LogitsConfig,\n",
    "    LogitsOutput,\n",
    "    ProteinType,\n",
    ")\n",
    "\n",
    "model = client(\n",
    "    model=\"esmc-300m-2024-12\", url=\"https://forge.evolutionaryscale.ai\", token=\"1hM3JVqy7zILco2fwPgF9v\"\n",
    ")\n",
    "\n",
    "EMBEDDING_CONFIG = LogitsConfig(\n",
    "    sequence=True, return_embeddings=True, return_hidden_states=True\n",
    ")\n",
    "\n",
    "\n",
    "def embed_sequence(model: ESM3InferenceClient, sequence: str) -> LogitsOutput:\n",
    "    protein = ESMProtein(sequence=sequence)\n",
    "    protein_tensor = model.encode(protein)\n",
    "    output = model.logits(protein_tensor, EMBEDDING_CONFIG)\n",
    "    return output\n",
    "\n",
    "\n",
    "def batch_embed(\n",
    "    model: ESM3InferenceClient, inputs: Sequence[ProteinType]\n",
    ") -> Sequence[LogitsOutput]:\n",
    "    \"\"\"Forge supports auto-batching. So batch_embed() is as simple as running a collection\n",
    "    of embed calls in parallel using asyncio.\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(embed_sequence, model, protein) for protein in inputs\n",
    "        ]\n",
    "        results = []\n",
    "        for future in futures:\n",
    "            try:\n",
    "                results.append(future.result())\n",
    "            except Exception as e:\n",
    "                results.append(ESMProteinError(500, str(e)))\n",
    "    return results\n",
    "\n",
    "\n",
    "def read_fasta_fast(fasta_file):\n",
    "    records = []\n",
    "    with open(fasta_file) as in_handle:\n",
    "        for title, seq in SimpleFastaParser(in_handle):\n",
    "            gene_id = title.split()[0]\n",
    "            records.append((gene_id, seq, len(seq)))\n",
    "    return pd.DataFrame(records, columns=[\"Gene\", \"Sequence\", \"Length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c7ca7",
   "metadata": {},
   "source": [
    "Run seq embedding on one fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"wtCaPETase\"\n",
    "# === Save outputs to pickle ===\n",
    "with open(f\"petase_db/sequences/esm3_seq/seq_embeddings/{name}_outputs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output, f)\n",
    "\n",
    "with open(f\"petase_db/sequences/esm3_seq/seq_embeddings/{name}_meanembeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_mean_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d55099",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = read_fasta_fast(\"petase_db/sequences/esm3_seq/wtCaPETase.fasta\")\n",
    "seq = input[\"Sequence\"].to_list()\n",
    "output = batch_embed(model, seq)\n",
    "\n",
    "# we'll summarize the embeddings using their mean across the sequence dimension\n",
    "all_mean_embeddings = [\n",
    "    torch.mean(o.hidden_states, dim=0).squeeze().cpu()\n",
    "    for o in output\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f894a",
   "metadata": {},
   "source": [
    "note that all_mean_embeddings is the mean collapsing all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ecd0275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([295, 960])\n"
     ]
    }
   ],
   "source": [
    "print(all_mean_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a55ea",
   "metadata": {},
   "source": [
    "Batch input fasta files to embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f5f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished D1-PETase.fasta\n",
      "✅ Finished TM3-PETase.fasta\n",
      "✅ Finished DuraN233K.fasta\n",
      "✅ Finished CaPETase_T250N.fasta\n",
      "✅ Finished wtCaPETase.fasta\n",
      "✅ Finished wtLCC.fasta\n",
      "✅ Finished wtIsPETase_signaltrim.fasta\n",
      "✅ Finished LCC_variants_tournier.fasta\n",
      "✅ Finished FAST-PETase.fasta\n",
      "✅ Finished IsPETase_W159H_F229Y.fasta\n",
      "✅ Finished BhrPETase_variants.fasta\n",
      "✅ Finished thermopetase.fasta\n",
      "✅ Finished CaPETasevariants.fasta\n",
      "✅ Finished HOT-PETase.fasta\n",
      "✅ Finished IsPETase_S238FW159H.fasta\n",
      "✅ Finished all_petase_variants.fasta\n",
      "✅ Finished DuraPETase.fasta\n",
      "✅ Finished TS-PETase.fasta\n",
      "✅ Finished wtBhrPETase.fasta\n"
     ]
    }
   ],
   "source": [
    "#for the sequences\n",
    "for file in os.listdir(\"petase_db/sequences/esm3_seq\"):\n",
    "    if file.endswith(\".fasta\"):\n",
    "        fasta_path = os.path.join(\"petase_db/sequences/esm3_seq\", file)\n",
    "\n",
    "        # load sequences\n",
    "        df = read_fasta_fast(fasta_path)\n",
    "        seq = df[\"Sequence\"].to_list()\n",
    "\n",
    "        # run embeddings\n",
    "        output = batch_embed(model, seq)\n",
    "\n",
    "        # summarize mean embeddings\n",
    "        all_mean_embeddings = [\n",
    "            torch.mean(o.hidden_states, dim=0).squeeze().cpu()\n",
    "            for o in output\n",
    "        ]\n",
    "\n",
    "        name = os.path.splitext(file)[0]\n",
    "        # === Save outputs to pickle ===\n",
    "        with open(f\"petase_db/sequences/esm3_seq/seq_embeddings/{name}_outputs.pkl\", \"wb\") as f:\n",
    "            pickle.dump(output, f)\n",
    "        with open(f\"petase_db/sequences/esm3_seq/seq_embeddings/{name}_meanembeddings.pkl\", \"wb\") as f:\n",
    "            pickle.dump(all_mean_embeddings, f)\n",
    "        print(f\"✅ Finished {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf91e1",
   "metadata": {},
   "source": [
    "struct embed single pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install esm huggingface_hub  (once)\n",
    "from huggingface_hub import login\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESMProtein, SamplingConfig\n",
    "\n",
    "# 0) (one time) auth so weights can download; you can skip if already logged in\n",
    "# login()  # uncomment if needed; follows the ESM README\n",
    "\n",
    "PDB_PATH = \"petase_db/structures/wtIsPETase_6ilw_Repair.pdb\"\n",
    "CHAIN_ID = \"A\"\n",
    "\n",
    "# 1) Load structure into an ESMProtein\n",
    "#    Prefer the direct helper; fallback uses ProteinChain if your wheel exposes that API.\n",
    "try:\n",
    "    protein = ESMProtein.from_pdb(PDB_PATH, chain_id=CHAIN_ID)\n",
    "except AttributeError:\n",
    "    # Fallback path used in ESM examples circulating online\n",
    "    from esm.utils.structure.protein_chain import ProteinChain\n",
    "    protein = ESMProtein.from_protein_chain(\n",
    "        ProteinChain.from_pdb(PDB_PATH, chain_id=CHAIN_ID)\n",
    "    )\n",
    "\n",
    "# Load ESM3 open weights and encode\n",
    "\n",
    "protein_tensor = model.encode(protein)               \n",
    "# 4) Forward with embeddings requested\n",
    "out = model.forward_and_sample(\n",
    "    protein_tensor,\n",
    "    SamplingConfig(\n",
    "        return_per_residue_embeddings=True,\n",
    "        return_mean_embedding=True\n",
    "    )\n",
    ")\n",
    "\n",
    "import pickle\n",
    "with open(\"esm3_output.pkl\", \"wb\") as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "# 5) Grab embeddings\n",
    "per_residue = out.per_residue_embedding   # shape [L, D]\n",
    "mean_embed  = out.mean_embedding          # shape [D]\n",
    "print(per_residue.shape, mean_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af860149",
   "metadata": {},
   "source": [
    "structure embedding (batch pdb files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c368ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for structures\n",
    "EMBEDDING_CONFIG = LogitsConfig(\n",
    "    sequence=True, return_embeddings=True, return_hidden_states=True\n",
    ")\n",
    "for file in os.listdir(\"petase_db/structures/esm3_struct\"):\n",
    "    if file.endswith(\".pdb\"):\n",
    "        pdb_path = os.path.join(\"petase_db/structures/esm3_struct\", file)\n",
    "        CHAIN_ID = \"A\"\n",
    "        # 1) Load structure into an ESMProtein\n",
    "        #    Prefer the direct helper; fallback uses ProteinChain if your wheel exposes that API.\n",
    "        try:\n",
    "            protein = ESMProtein.from_pdb(pdb_path, chain_id=CHAIN_ID)\n",
    "        except AttributeError:\n",
    "            # Fallback path used in ESM examples circulating online\n",
    "            from esm.utils.structure.protein_chain import ProteinChain\n",
    "            protein = ESMProtein.from_protein_chain(\n",
    "                ProteinChain.from_pdb(pdb_path, chain_id=CHAIN_ID)\n",
    "            )\n",
    "        protein_tensor = model.encode(protein)\n",
    "        out = model.forward_and_sample(protein_tensor,SamplingConfig(return_per_residue_embeddings=True, return_mean_embedding=True))\n",
    "        per_residue = out.per_residue_embedding   # shape [L, D]\n",
    "        mean_embed  = out.mean_embedding          # shape [D]\n",
    "\n",
    "        name = os.path.splitext(file)[0]\n",
    "        # === Save outputs to pickle ===\n",
    "        with open(f\"petase_db/structures/esm3_struct/embeddings_struct/{name}_outputs.pkl\", \"wb\") as f:\n",
    "            pickle.dump(out, f)\n",
    "        with open(f\"petase_db/structures/esm3_struct/embeddings_struct/{name}_meanembeddings.pkl\", \"wb\") as f:\n",
    "            pickle.dump(mean_embed, f)\n",
    "        print(f\"✅ Finished {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d85eb8",
   "metadata": {},
   "source": [
    "PLMSol \n",
    "\n",
    "`conda env create -f env.yml`\n",
    "\n",
    "`pip install --upgrade pip setuptools wheel `\n",
    "\n",
    "`conda activate PLM_Sol`\n",
    "\n",
    "`conda install -c conda-forge cython`\n",
    "\n",
    "`pip install --upgrade pip setuptools wheel`\n",
    "\n",
    "`pip install \"numpy>=1.24\" \"scikit-learn>=1.3\"`\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "`pip install --no-deps \"bio-embeddings[all]\"`\n",
    "\n",
    "`pip install \"gensim>=4.0\" plotly humanize ruamel.yaml python-slugify`\n",
    "\n",
    "`pip install \"numpy>=1.24\" \"scikit-learn>=1.3\" \"torch>=2.0\" \"pandas>=2.0\"`\n",
    "\n",
    "`pip install appdirs atomicwrites importlib_metadata lock tqdm umap-learn`\n",
    "\n",
    "`pip install --no-deps bio-embeddings`\n",
    "\n",
    "`cd embedding_datset`\n",
    "\n",
    "`pip install \"ruamel.yaml<0.18.0,>=0.17.10\"`\n",
    "\n",
    "`pip install \"bio-embeddings[prottrans_t5_xl_u50]\" --no-deps`\n",
    "\n",
    "`pip install transformers==4.30.2 tokenizers==0.13.3 sentencepiece==0.1.99`\n",
    "\n",
    "`bio_embeddings embedding_protT5.yml `\n",
    "\n",
    "but now it requires downloading 85Gb of embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252a89e",
   "metadata": {},
   "source": [
    "protsolm\n",
    "conda create -n protsolm python=3.10                             \n",
    "conda activate protsolm\n",
    "pip install -r requirements.txt\n",
    "pip install --upgrade pip setuptools wheel cython            \n",
    "pip install \"numpy==1.23.5\"                  \n",
    "pip install --force-reinstall biotite==0.34.0\n",
    "pip install torch biopython tqdm pandas mdtraj \n",
    " \n",
    " but now stuck at getting features MD 84k pdbs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e577a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "febd94f0",
   "metadata": {},
   "source": [
    "GATSol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27639908",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
